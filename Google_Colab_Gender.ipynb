{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttlenh04/AI-hackathon---Face-analysis-challenge/blob/main/Google_Colab_Gender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVpyydSL1FmA"
      },
      "outputs": [],
      "source": [
        "# @title Unzip tệp test\n",
        "!unzip '/content/drive/MyDrive/public_test.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SN21fI07l3Q"
      },
      "source": [
        "Thay thế đường link bằng link google drive đã được nén thành file zip của tập data (lưu ý đoạn mã chỉ chạy một tập train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxqLkaWZ7jLI"
      },
      "source": [
        "Vào quá trình thực hiện"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAiJl_mT7weJ"
      },
      "source": [
        "Thay thế đường link file json file_name_to_imgae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEfNGbVH7Xwf"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP0p4QHU17Mo",
        "outputId": "254d2a44-c0ae-4c5d-fb68-5b3ee4bbd505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Các image_id bị trùng:\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import display, Image\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Đường dẫn tới thư mục chứa hình ảnh\n",
        "image_folder_path = '/content/public_test'\n",
        "\n",
        "# Đường dẫn tới file JSON\n",
        "json_file_path = '/content/drive/MyDrive/file_name_to_image_id.json'\n",
        "\n",
        "# Đọc nội dung từ file JSON\n",
        "with open(json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "\n",
        "# Tạo một từ điển để theo dõi số lần xuất hiện của mỗi image_id\n",
        "image_id_counts = {}\n",
        "\n",
        "# Tạo danh sách để lưu trữ các image_id bị trùng\n",
        "duplicate_image_ids = []\n",
        "\n",
        "# Lặp qua các file trong thư mục\n",
        "for image_name, image_id in json_data.items():\n",
        "    # Kiểm tra xem image_id đã xuất hiện trong từ điển chưa\n",
        "    if image_id in image_id_counts:\n",
        "        image_id_counts[image_id] += 1\n",
        "        # Nếu image_id đã xuất hiện trước đó, thêm vào danh sách image_id bị trùng\n",
        "        if image_id not in duplicate_image_ids:\n",
        "            duplicate_image_ids.append(image_id)\n",
        "    else:\n",
        "        image_id_counts[image_id] = 1\n",
        "\n",
        "# In ra các image_id bị trùng\n",
        "print(\"Các image_id bị trùng:\")\n",
        "for duplicate_id in duplicate_image_ids:\n",
        "    print(duplicate_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gi7u3Tc8IGZ"
      },
      "source": [
        "Đoạn mã train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_FEBLcK8ESZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6SaH24R8HTX"
      },
      "outputs": [],
      "source": [
        "!pip install -U torchvision # We need a new versino of torchvision for this project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7jP52V78Y2m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, models\n",
        "from torchvision.transforms import functional as FT\n",
        "from torchvision import transforms as T\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, sampler, random_split, Dataset\n",
        "import copy\n",
        "import math\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import albumentations as A  # our data augmentation library\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtTudKPK8a8I"
      },
      "outputs": [],
      "source": [
        "# remove arnings (optional)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from collections import defaultdict, deque\n",
        "import datetime\n",
        "import time\n",
        "from tqdm import tqdm # progress bar\n",
        "from torchvision.utils import draw_bounding_boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oBqpTeJ8cVu"
      },
      "outputs": [],
      "source": [
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YkYLaKf8d1S"
      },
      "outputs": [],
      "source": [
        "# our dataset is in cocoformat, we will need pypcoco tools\n",
        "!pip install pycocotools\n",
        "from pycocotools.coco import COCO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BseEWI7o8f3i"
      },
      "outputs": [],
      "source": [
        "# Now, we will define our transforms\n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdBMEC-I8jsI"
      },
      "source": [
        "Tới đoạn code thực thi chỉnh sửa tệp đầu vào"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BUvnupC8oUa"
      },
      "outputs": [],
      "source": [
        "def get_transforms(train=False):\n",
        "    if train:\n",
        "        transform = A.Compose([\n",
        "            A.Resize(600, 600), # our input size can be 600px\n",
        "            ToTensorV2()\n",
        "        ], bbox_params=A.BboxParams(format='coco'))\n",
        "    else:\n",
        "        transform = A.Compose([\n",
        "            A.Resize(600, 600), # our input size can be 600px\n",
        "            ToTensorV2()\n",
        "        ], bbox_params=A.BboxParams(format='coco'))\n",
        "    return transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsaNorS68qIB"
      },
      "outputs": [],
      "source": [
        "class AquariumDetection(datasets.VisionDataset):\n",
        "    def __init__(self, root, split='train', transform=None, target_transform=None, transforms=None):\n",
        "        # the 3 transform parameters are reuqired for datasets.VisionDataset\n",
        "        super().__init__(root, transforms, transform, target_transform)\n",
        "        self.split = split #train, valid, test\n",
        "        self.coco = COCO(os.path.join(root, split, \"_annotations.coco.json\")) # annotatiosn stored here\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "        self.ids = [id for id in self.ids if (len(self._load_target(id)) > 0)]\n",
        "\n",
        "    def _load_image(self, id: int):\n",
        "        path = self.coco.loadImgs(id)[0]['file_name']\n",
        "        image = cv2.imread(os.path.join(self.root, self.split, path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        return image\n",
        "    def _load_target(self, id):\n",
        "        return self.coco.loadAnns(self.coco.getAnnIds(id))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        id = self.ids[index]\n",
        "        image = self._load_image(id)\n",
        "        target = self._load_target(id)\n",
        "        target = copy.deepcopy(self._load_target(id))\n",
        "\n",
        "        boxes = [t['bbox'] + [t['category_id']] for t in target] # required annotation format for albumentations\n",
        "        if self.transforms is not None:\n",
        "            transformed = self.transforms(image=image, bboxes=boxes)\n",
        "\n",
        "        image = transformed['image']\n",
        "        boxes = transformed['bboxes']\n",
        "\n",
        "        new_boxes = [] # convert from xywh to xyxy\n",
        "        for box in boxes:\n",
        "            xmin = box[0]\n",
        "            xmax = xmin + box[2]\n",
        "            ymin = box[1]\n",
        "            ymax = ymin + box[3]\n",
        "            new_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "        boxes = torch.tensor(new_boxes, dtype=torch.float32)\n",
        "\n",
        "        targ = {} # here is our transformed target\n",
        "        targ['boxes'] = boxes\n",
        "        targ['labels'] = torch.tensor([t['category_id'] for t in target], dtype=torch.int64)\n",
        "        targ['image_id'] = torch.tensor([t['image_id'] for t in target])\n",
        "        targ['area'] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]) # we have a different area\n",
        "        targ['iscrowd'] = torch.tensor([t['iscrowd'] for t in target], dtype=torch.int64)\n",
        "        return image.div(255), targ # scale images\n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wWwxDXp9Fr_"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/gender.zip' #Thay thế đường dẫn tập data cần huấn luyện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcA13AWR9Gpi"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88drYhc39I9v"
      },
      "outputs": [],
      "source": [
        "#load classes\n",
        "coco = COCO(os.path.join(dataset_path, \"train\", \"_annotations.coco.json\"))\n",
        "categories = coco.cats\n",
        "n_classes = len(categories.keys())\n",
        "categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9opRMf3S9K--"
      },
      "outputs": [],
      "source": [
        "classes = [i[1]['name'] for i in categories.items()]\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt-FGfpP9MPY"
      },
      "outputs": [],
      "source": [
        "train_dataset = AquariumDetection(root=dataset_path, transforms=get_transforms(True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omiag1Gc9N9G"
      },
      "outputs": [],
      "source": [
        "# Lets view a sample\n",
        "sample = train_dataset[2]\n",
        "img_int = torch.tensor(sample[0] * 255, dtype=torch.uint8)\n",
        "plt.imshow(draw_bounding_boxes(\n",
        "    img_int, sample[1]['boxes'], [classes[i] for i in sample[1]['labels']], width=4\n",
        ").permute(1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6Ra0LHR9PEf"
      },
      "outputs": [],
      "source": [
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHWKEG4b91vh"
      },
      "outputs": [],
      "source": [
        "# lets load the faster rcnn model\n",
        "model = models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features # we need to change the head\n",
        "model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv7dkncv9QWZ"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FG7yI6Va9RkP"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MCSraRU9UMY"
      },
      "outputs": [],
      "source": [
        "images,targets = next(iter(train_loader))\n",
        "images = list(image for image in images)\n",
        "targets = [{k:v for k, v in t.items()} for t in targets]\n",
        "output = model(images, targets) # just make sure this runs without error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJgN6o2A9WEP"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") # use GPU to train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "La7s0K4O9XnX"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz-1ULwb9Yqe"
      },
      "outputs": [],
      "source": [
        "# Now, and optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9, nesterov=True, weight_decay=1e-4)\n",
        "# lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[16, 22], gamma=0.1) # lr scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amNIbmNl9aE2"
      },
      "outputs": [],
      "source": [
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHZ70PYV9b9R"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, loader, device, epoch):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "#     lr_scheduler = None\n",
        "#     if epoch == 0:\n",
        "#         warmup_factor = 1.0 / 1000 # do lr warmup\n",
        "#         warmup_iters = min(1000, len(loader) - 1)\n",
        "\n",
        "#         lr_scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor = warmup_factor, total_iters=warmup_iters)\n",
        "\n",
        "    all_losses = []\n",
        "    all_losses_dict = []\n",
        "\n",
        "    for images, targets in tqdm(loader):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: torch.tensor(v).to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets) # the model computes the loss automatically if we pass in targets\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        loss_dict_append = {k: v.item() for k, v in loss_dict.items()}\n",
        "        loss_value = losses.item()\n",
        "\n",
        "        all_losses.append(loss_value)\n",
        "        all_losses_dict.append(loss_dict_append)\n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(f\"Loss is {loss_value}, stopping trainig\") # train if loss becomes infinity\n",
        "            print(loss_dict)\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "#         if lr_scheduler is not None:\n",
        "#             lr_scheduler.step() #\n",
        "\n",
        "    all_losses_dict = pd.DataFrame(all_losses_dict) # for printing\n",
        "    print(\"Epoch {}, lr: {:.6f}, loss: {:.6f}, loss_classifier: {:.6f}, loss_box: {:.6f}, loss_rpn_box: {:.6f}, loss_object: {:.6f}\".format(\n",
        "        epoch, optimizer.param_groups[0]['lr'], np.mean(all_losses),\n",
        "        all_losses_dict['loss_classifier'].mean(),\n",
        "        all_losses_dict['loss_box_reg'].mean(),\n",
        "        all_losses_dict['loss_rpn_box_reg'].mean(),\n",
        "        all_losses_dict['loss_objectness'].mean()\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thực hiện việc train model\n"
      ],
      "metadata": {
        "id": "wIUtEpyrXwBT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYhOhwOl9eJO"
      },
      "outputs": [],
      "source": [
        "num_epochs=50\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
        "#     lr_scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiến hành đánh giá model"
      ],
      "metadata": {
        "id": "6aRG9fZXX3jz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQJ2cXBaAgkJ"
      },
      "outputs": [],
      "source": [
        "def calculate_iou(box1, box2):\n",
        "    x1, y1, w1, h1 = box1\n",
        "    x2, y2, w2, h2 = box2\n",
        "\n",
        "    # Tính toán tọa độ của hộp giao nhau\n",
        "    x_intersection = max(x1, x2)\n",
        "    y_intersection = max(y1, y2)\n",
        "    w_intersection = min(x1 + w1, x2 + w2) - x_intersection\n",
        "    h_intersection = min(y1 + h1, y2 + h2) - y_intersection\n",
        "\n",
        "    # Tính toán diện tích phần giao và phần hợp\n",
        "    area_intersection = max(0, w_intersection) * max(0, h_intersection)\n",
        "    area_union = w1 * h1 + w2 * h2 - area_intersection\n",
        "\n",
        "    # Tính toán IoU\n",
        "    iou = area_intersection / max(area_union, 1e-10)\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HZ9xAAyP8fQ"
      },
      "outputs": [],
      "source": [
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thực hiện lưu kết quả dự đoán vào file xlsx\n"
      ],
      "metadata": {
        "id": "g9rbkdezYB6V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ovRFSWj4_s34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "7798b4fe-331d-471b-d81a-a3ff2a52c624"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/public_test/100147591.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b8a556ff3db6>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Đọc hình ảnh từ đường dẫn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Áp dụng các biến đổi cho hình ảnh nếu cần\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/public_test/100147591.jpg'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Chọn thiết bị (CPU hoặc GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Ngưỡng độ tin cậy để coi một dự đoán là đúng\n",
        "confidence_threshold = 0.5\n",
        "\n",
        "# Tên các lớp trong COCO dataset\n",
        "coco_classes = [\n",
        "    \"Female\", \"Male\", \"Female\"\n",
        "]\n",
        "\n",
        "# Đường dẫn đến thư mục chứa hình ảnh test\n",
        "test_folder_path = '/content/public_test'\n",
        "\n",
        "# Đường dẫn đến file JSON\n",
        "json_file_path = '/content/drive/MyDrive/file_name_to_image_id.json'\n",
        "\n",
        "# Đọc nội dung từ file JSON\n",
        "with open(json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "\n",
        "# Tạo danh sách để lưu thông tin\n",
        "file_names = []\n",
        "image_ids = []\n",
        "emotions = []\n",
        "all_boxes = []  # Danh sách chứa thông tin của tất cả các bounding box\n",
        "\n",
        "# Tạo DataFrame để tổ chức dữ liệu\n",
        "data = {'File Name': [], 'Image ID': [], 'Gender': [], 'Box': []}\n",
        "\n",
        "# Duyệt qua từng hình ảnh và thực hiện dự đoán\n",
        "for image_name, image_id in json_data.items():\n",
        "    # Đường dẫn đầy đủ đến hình ảnh\n",
        "    image_path = os.path.join(test_folder_path, image_name)\n",
        "\n",
        "    # Đọc hình ảnh từ đường dẫn\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    # Áp dụng các biến đổi cho hình ảnh nếu cần\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    img_tensor = transform(img).to(device)\n",
        "\n",
        "    # Dự đoán nhãn sử dụng mô hình (chưa có mô hình được định nghĩa trong mã của bạn)\n",
        "    # Đặt tên mô hình của bạn ở đây, ví dụ: model = your_custom_model()\n",
        "    with torch.no_grad():\n",
        "        prediction = model(img_tensor.unsqueeze(0))\n",
        "\n",
        "    # Kiểm tra nếu có dự đoán hoặc không\n",
        "    if prediction[0]['scores'].cpu().numpy().size > 0:\n",
        "        # Lấy dự đoán có độ tin cậy cao nhất\n",
        "        top_prediction = max(prediction[0]['scores'].cpu().numpy())\n",
        "        top_index = np.argmax(prediction[0]['scores'].cpu().numpy())\n",
        "        top_class = coco_classes[prediction[0]['labels'].cpu().numpy()[top_index]]\n",
        "\n",
        "        # Lấy thông tin vị trí bounding box\n",
        "        top_box = prediction[0]['boxes'].cpu().numpy()[top_index]\n",
        "    else:\n",
        "        # Nếu không có dự đoán, sử dụng giá trị mặc định là \"Happiness\"\n",
        "        top_prediction = 0.0\n",
        "        top_index = -1\n",
        "        top_class = \"Female\"\n",
        "        top_box = [0.0, 0.0, 0.0, 0.0]\n",
        "\n",
        "    # Lưu thông tin vào danh sách và DataFrame\n",
        "    file_names.append(image_name)\n",
        "    image_ids.append(image_id)\n",
        "    emotions.append(top_class)\n",
        "    all_boxes.append(top_box)\n",
        "\n",
        "    # Thêm dữ liệu vào DataFrame\n",
        "    data['File Name'].append(image_name)\n",
        "    data['Image ID'].append(image_id)\n",
        "    data['Gender'].append(top_class)\n",
        "    data['Box'].append(top_box)\n",
        "\n",
        "# Đảm bảo rằng số lượng phần tử trong các list là bằng nhau\n",
        "while len(file_names) < len(json_data):\n",
        "    file_names.append(None)\n",
        "    image_ids.append(None)\n",
        "    emotions.append(\"Female\")\n",
        "    all_boxes.append([0.0, 0.0, 0.0, 0.0])\n",
        "\n",
        "# Tạo DataFrame từ dữ liệu\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ghi DataFrame vào file Excel\n",
        "excel_output_path = '/content/drive/MyDrive/gender.xlsx'\n",
        "df.to_excel(excel_output_path, index=False)\n",
        "\n",
        "print(f\"Dữ liệu và dự đoán đã được lưu vào file Excel: {excel_output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hiển thị dự đoán"
      ],
      "metadata": {
        "id": "dr9CHWpHYNUc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hQ7XyW2lb4AX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Chọn thiết bị (CPU hoặc GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Ngưỡng độ tin cậy để coi một dự đoán là đúng\n",
        "confidence_threshold = 0.5\n",
        "\n",
        "# Tên các lớp trong COCO dataset\n",
        "coco_classes = [\n",
        "    \"Female\", \"Male\", \"Female\"\n",
        "]\n",
        "\n",
        "# Đường dẫn đến thư mục chứa hình ảnh test\n",
        "test_folder_path = '/content/public_test'\n",
        "\n",
        "# Đường dẫn đến file JSON\n",
        "json_file_path = '/content/drive/MyDrive/file_name_to_image_id.json'\n",
        "\n",
        "# Đọc nội dung từ file JSON\n",
        "with open(json_file_path, 'r') as json_file:\n",
        "    json_data = json.load(json_file)\n",
        "\n",
        "# Tạo danh sách để lưu thông tin\n",
        "file_names = []\n",
        "image_ids = []\n",
        "emotion = []\n",
        "all_boxes = []  # Danh sách chứa thông tin của tất cả các bounding box\n",
        "\n",
        "# Tạo DataFrame để tổ chức dữ liệu\n",
        "data = {'File Name': [], 'Image ID': [], 'Gender': [], 'Box': []}\n",
        "\n",
        "# Duyệt qua từng hình ảnh và thực hiện dự đoán\n",
        "for image_name, image_id in json_data.items():\n",
        "    # Đường dẫn đầy đủ đến hình ảnh\n",
        "    image_path = os.path.join(test_folder_path, image_name)\n",
        "\n",
        "    # Đọc hình ảnh từ đường dẫn\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    # Áp dụng các biến đổi cho hình ảnh nếu cần\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    img_tensor = transform(img).to(device)\n",
        "\n",
        "    # Dự đoán nhãn sử dụng mô hình (đặt tên mô hình của bạn ở đây)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = model(img_tensor.unsqueeze(0))\n",
        "\n",
        "    # Kiểm tra nếu có dự đoán hoặc không\n",
        "    if prediction[0]['scores'].cpu().numpy().size > 0:\n",
        "        # Lấy dự đoán có độ tin cậy cao nhất\n",
        "        top_prediction = max(prediction[0]['scores'].cpu().numpy())\n",
        "        top_index = np.argmax(prediction[0]['scores'].cpu().numpy())\n",
        "        top_class = coco_classes[prediction[0]['labels'].cpu().numpy()[top_index]]\n",
        "\n",
        "        # Lấy thông tin vị trí bounding box\n",
        "        top_box = prediction[0]['boxes'].cpu().numpy()[top_index]\n",
        "\n",
        "        # Hiển thị hình ảnh và bounding box với nhãn lớp\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        ax = plt.gca()\n",
        "\n",
        "        # Hiển thị hình ảnh\n",
        "        ax.imshow(img)\n",
        "\n",
        "        # Hiển thị bounding box và nhãn lớp\n",
        "        rect = patches.Rectangle(\n",
        "            (top_box[0], top_box[1]),\n",
        "            top_box[2] - top_box[0],\n",
        "            top_box[3] - top_box[1],\n",
        "            linewidth=2,\n",
        "            edgecolor='r',\n",
        "            facecolor='none',\n",
        "            label=top_class\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "        # Đặt tiêu đề là tên lớp dự đoán\n",
        "        ax.set_title(top_class)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        print(f\"Không có dự đoán cho hình ảnh: {image_name}\")\n",
        "\n",
        "print(\"Hoàn thành dự đoán và hiển thị trên hình ảnh.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1rAeSgmuYYnQF87zdrf3Cga8PfnchnmtJ",
      "authorship_tag": "ABX9TyPaJxt8fmp+g0bGgWcbl7BA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}